CNN
사용이유
이미지와 같은 2D 이상의 차원을 갖는 데이터는 MLP(다층 퍼셉트론)으로 데이터 속성 자체를 그대로 처리 하지 못함
적은 수의 가중치로 이미지 처리를 효율적으로 할 수 있음


필터

필터의 개수가 출력의 레이어를 결정

출력 크기 계산
(inh + 2P - filterh)/ s + 1

패딩과 풀링


CNN의 성능을 높이는 방법
데이터의 양을 늘린다.(keras의 ImageDataGenerator)
(데이터를 합성해 여러가지 방법으로 1개의 데이터를 여러개 만들 수 있다)

Ensemble
인풋 1개를 한번만 계산하는 것이 아닌 여러개의 클래스로 나누어 계산한다. 이때 각 클래스에서 나온 결과들을 Merge해 softmax로 계산.

---------------------------------------------------

RNN
등장이유 : 시퀀스 데이터를 모델링하기 위해.
이전 데이터에 대한 출력이 현재 데이터에도 영향을 줌.
순환구조

return_sequences
이것은 stacked RNN에서 TRUE 지정이 중요

RNN을 사용할 때 입력의 크기가 다를 수 있기 때문에 패딩을 사용한다.
이때 패딩에 대한 로스값과 결과들은 무시되어야 함.
이때 패딩을 사용했다는 것을 구분짓는 것이 마스킹

시퀀스 마스킹의 방법
keras.layer.Masking을 사용
임베딩을 할 때 zero_padding값을 True로 준다.
RNN 레이어를 호출할 때 패딩인수를 수동으로 전달.


RNN단점. 
입력 데이터가 커질수록 학습능력의 저하
데이터의 뒤로갈수록 앞의 데이터 정보 손실.
입출력 데이터간의 거리가 멀어질 수록 연관관계가 줄어든다.(장기의존성)

장기의존성을 해결한 모델
LSTM

RNN의 히든스테이트에 cell state를 추가
forget gate layer, input gate layer, output gate layer
오래걸려도 그레디언트가 비교적 전파.


@forget gate layer. 
앞에 있는 레이어의 입력값 필요결정
(시그모이드 레이어)
ft = o(Wf * [ht-1,x] + bf)

@input gate layer
it = o(Wf * [ht-1,xt] + bi)
Ct~ = tanh(Wc* [ht-1,xt] + bc)
강도의 결정

이 두개에 대한 product를 이용한다. 그래서 현재 있는 입력을 기준으로 전 데이터가 얼마만큼의 영향을 주는지 결정.
 Ct = ft * Ct-1 + it * ~Ct


@output layer
ot = o(Wo[ht-1,xt] + bo)
ht = ot * tanh(Ct)


GRU
LSTM에서 forget과 inpute 게이트 레이어를 합친 형태이다.
Ct = ft * Ct-1 + (1-ft)*~Ct


원 핫 인코딩
새로운 피처를 추가해 고유값에 해당하는 열에만 1 나머진 0
n-1개의 차원 필요.

임베딩.
범주형 자료를 연속성 벡터 형태로 변환
하는이유(장점)
차원을 축소할 수 있다.
onehot 인코딩으로 표현할 경우 n-1개의 차원 필요 반면 임베딩은 2,3차원으로도 자료를 표현가능.
범주형 자료를 연속형으로 표현할 수 있다
§ 의미를 도출하기에 용이하다

ModelCheckpoint
로스값이 다시 올라갈때 방지
최저값을 저장하고 있다가 더 최저가 나오면 갱신.

EarlyStopping
러닝 데이터값이 너무 커질 경우 종료
--------------------------------------------------------------

GAN(적대적 신경망)
생성자와 판별자.

생성자(generator)
가짜를 만든다
DCGAN은 생성자가 가짜이미지 생성시 CNN이용

특징:
옵티마이저를 사용하는 최적화나 컴파일과정이 없다
일부 매개변수를 삭제하는 풀링이 없고 대신 패딩만 존재
입력과 출력의 크기가 같아야 하기 때문이다.

필수적으로 필요한 옵션:
배치정규화(평균 0 표준편차1이 되도록 재배치)
활성화 함수로 ReLU함수, 판별자로 넘겨 주기 직전에 tanh함수(ReLU대신 LeakyReLU도 사용)

unsupervisied Learing 비지도학습
생성자는 비지도학습이다.누군가 데이터를 준 것이 아니다.

supervised Learning
판별자는 지도학습입니다. 가짜인지 진짜인지 원래 있기 때문에 지도학습입니다.


Auto Encoder
데이터를 효율적으로 코딩 즉 압축.
데이터를 효율적으로 나타내기 위해서 고차원을 저차원으로.
임력층과 출력층이 같도록 한다. 은닉층을 기준으로 좌우 대칭

신경망 기반 비지도학습 기법으로 차원축소, 이미지 압축, 이미지 노이즈 제거,
이미지 생성 등에 사용되는 신경망 구조

오토인코더의 가장 큰 특징은 입력을 다시 라벨
