기계 6주차
케라스.

케라스를 이용해 예측
강의 자료에서 코드가 있는데

model.compile (loss='mean_squared_error',optimizer='SGD')
여기까지는 모델을 만드는 것이다, 하지만 우리는 w값을 원래는 모른다.

다만 정확히 나오는지 봐야해서 적어놓은 것이다.
이거 코드는 따로 메모장에 저장.

우리가 캐러스로 학습할때 로스값이랑 정확도가 어떤지 그림으로 보기 위한것이
callback옵션이다. 이거는 fit안에 옵션으로 적는 것이다.

작업하는 디렉토리로 들어가면 tensorboard --logdir = ./graph로 사용하면 댄다.(cmd실행)
그러면 주소가 뜨는데 이걸 브라우저로 실행

레이어를 여러개 줄 경우 정확도가 더 높아질 수 있다.
model.add(Dense(2,input_shape=(1,)))
model.add(Dense(2,))
model.add(Dense(2,))
model.add(Dense(2,))
이게 시작 레이어를 여러개 준 것
하지만 레이어를 많이 준다고 좋아지는 것도 아니다.
xor예제의 레이어를 높이면 더 좋지 않은 결과가 나온다. 

이유는 activation 함수 즉 활성화 함수 때문이다.
경사하강법에서 적당한 스탭을 찾아야 정확한 값으로 갈 수 있다.

------------------------------------------------
다층 퍼셉트론

은닉층이 2개 이상일때 심층 신경망이라 하며 이를 학습하여 만든 모델을 딥 러닝이라고 한다.


각각의 레이어들마다 w값이 있는데 이것을 어떻게 알고 찾아내야 할가
이걸 해결하는것이 역천파이다.

역전파
층이 깊어질 수록 증가하는 가중치 매개변수의 수로 인해 다층 퍼셉트론을 학습시키기에는 오랜 시간이 걸리는 문제가 발생

입력으로 넣어주고 출력층까지 각층의 뉴런마다 출력계산. 이를 순전파 라고 한다.

마지막 출력층에 대한 결과와 실제값과의 오차를 계산(손실함수 이용 로스펑션)

그리고 오차를 역방향으로 흘러 보내면서 각 출력 뉴런의 오차에 마지막 입력 뉴런이 얼마나 기여햇는지 측정.
즉 각 뉴런의 입력값에 대한 손실함수의 편미분, 그래디언트를 계산한것

3번과 같은 방법을 입력층에 도달할 때 까지 계속 반복해서 역방향으로 흘러보낸다.

계산한 그래디언트를 네트워크의 모든 가중치 매개변수에 반영해주는 경사하강법 단계를 수행한다.

정리하면 일정한 w값으로 레이어가 넘어가다 출력층에 도달하면 오차를 계산하며 다시 역으로 입력층까지 올라간다. 이과정을 통해 가장 적절한 w값을 찾는 것이다.

활성화 함수
역전파 알고리즘이 잘 동작하기 위해서 다층 퍼셉트론의 구조에 변화를 주었다.
활성화 함수는 여러가지가 있다.

각 데이터의 관계마다 최적의 활성화 함수들이 다르다. 그래서 어떤게 좋다라고 말하긴 힘들다. 상황에 따라 사용해야함.

plt.contourf(a,b,c) 
3차원 좌표(깊이까지 표현됨)

----------------------------------------------
Multinomial classification
다중분류

1. 여러선을 이용하여 나눈다.
이것을 이용하면
카라스의 softmax란 것이 있다.
결과값의 각각의 확률을 구한것이 softmax 이다
그래서 softmax값이 가장 큰 것이 그 라벨에 속한다 라고 얘기한다.
karas.layer.Dense(10,activation = "softmax")

plt.imshow(x_train[0],cmap='binary')
이미지를 만드는 것인데x로 만들되 cmap이 바이너리여서 흑백이다.

트레이닝 중에서도 모델 튜닝의 결과를 얼마나 정확한지 할 부분으로 validation 파트를 따로 만든다 

즉 트레이닝파트로 모델을 만들고 벨리데이션으로 검증하고 test로 최종을 한다.














