기계 3주차

SHAPE의 규칙(내적)
2차원에서는 (i,j) @ (j,K)
j부분이 같아야한다. 크기는 (i,k)

3차원에서는 (x,i,j) @ (x,j,k)로 처음 면 부분의 크기는 같아야 하고 뒤에 두개씩만 보면 2차원과 동일 크기는 (x,i,k)

전치행렬은 
3x2의 행렬을 2x3으로 바꾸는 것 처럼 행과 열을 바꾸는 것.

a.T

3차원 일때 .
(면,행,렬) 형태의 배열인데
Transpose(0,1,2) 즉 숫자가 0이 면의 크기 1이 행의 크기 2는 열의 크기를 가져온다고 생각하면 된다.


a= np.rand(4,2,3)으로 만들었다고 치자
a.transpose(2,1,0)을 하면
면은 4->3
행은 2->2
열은 3->4로 변환된다.


squeeze
필요없는 텐서를 없앤다.
만약 
a= np.rand(4,1,3) 인 것을 만들었을 때
a.squeeze()를 하면 (4,3)이 된다 즉 1인 부분은 사실 필요가 없기 때문에 지운것.

np.expand_dims(rand(4,2),axis = ?)?는 1을 추가할 위치
0은 면이 추가
1은 행이 추가
2는 열이 추가.

concatenate
합치는 것을 의미한다.
tensor_a = rand(4,1,2)
tensor_b = rand(4,1,2)
np.concatenate([tensor_a, tensor_b],axis = 0)
np.concatenate([tensor_a, tensor_b],axis = 1)
np.concatenate([tensor_a, tensor_b],axis = 2)
하면 모양은
(8,1,2)
(4,2,2)
(4,1,4)
로 나온다

나누는 것은 split(배열,나눌개수)로 나누는 것이 가능하다.

===============================
신경망과 딥러닝.

지도학습
-예측
-이진분류
-다중분류
공통적으로 선으로 분류를 하고 있다.
먼저 선들이 어디서 나왔는지 부터 공부한다.

numpy와 그림을 그리기 위한 matplotlib.pyplot을 임포트(아마도 기계하는 동안 계속 사용)

x와 y값이 같아야 한다.
plt.plot(x,y,'o') 
이렇게 하면 점들이 찍힌다. x와 y는 미리 랜덤한 값으로 지정을 했고 'o'를 적지 않으면 x와 y선들로 연결이 되어 마크를 주는것.
plt.show()

가장 좋은 선을 찾는 방법
y = ax + b
a는 기울기. b는 절편.
선과 점 y의 차가 오차인데 오차를 줄여야 한다.
Cost function (Loss Function)
각 점들의 오차를 제곱승 한다. 그래서 그 점의 개수만큼 나누면 cost함수이다 이 결과를 최소화하면 된다.

경사 하강법.
기울기를 0과 근접하게 가야한다.
즉 코스트값을 그래프로 그렸을 때 미분하여 기울기가 최대한 0에 가까워지도록 하는것

이것을 해주는 모듈이 있는데 sklearn.linear_model의 LinearRegression이다.
그래서 변수 a = LinearRegression()으로 모델을 생성하고 a.fit(x,y)로 xy값을 집어넣어준다.

기울기: a.fitter.coef_
절편 : a.fitter.intercept_

y_predicted = a.predict(x) #추측값 hat^
그래서 
plt.plot(x,y_predicted)로 하면 선이 나온다.


인공 신경망
모든 신경의 기본은 y= wx + b형태를 기반.

뉴런을 사용한 논리 연산.
C= A 항등함수
논리 곱 연산 : C = A^B 둘다 활성되야 함
논리 합 연산 : C = A V B 둘중 하나 활성되도 활성
어떤 입력이 뉴런 활성화를 억제.
A가 활성 B가 비활성일 때.
C = A ^ !B

퍼셉트론
신경망의 기원이 되는 알고리즘
딥러닝의 기원
다수의 신호를 입력으로 받아 하나의 신호로 출력
일력과 가중치의 합을 특정(계단)함수를 통해 출력하는 것.

신호 : 흐른다 흐르지않는다 두 가지 값을 가짐(0과 1)

§ 입력신호: x1, x2
§ 출력신호: y
§ 가중치: w1, w2(w는 weight의 머리글자)
§ 퍼셉트론에서는 가중치가 클수록 강한 신호를 흘림.
§ 전류에서 말하는 저항. 저항이 낮을 수록 큰 전류가 흐름.
§ 뉴런, 노드: x1, x2, y
§ 입력신호가 뉴런에 보내질 때 각각 고유한 가중치가 곱해짐. (w1x1, w2x2)
그래서 신호의 총 합이 일정치(세타 theta)를 넘어설 때만 1을 출력.

y = 0 (w1x1 +w2x2 <= theta)
y = 1 (w1x1 +w2x2 > theta)
























