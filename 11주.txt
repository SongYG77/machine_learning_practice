11주차 기계
CNN

CNN의 성능 높이는 방법

1. 데이터의 양 늘이기
그림의 특징을 찾는것이 중요한데 같은 그림을 여러가지 방법으로 변화시켜 비슷한 이미지를 여러개 만든다.(색상, 각도 등등)

Keras의  ImageDataGenerator 함수가 데이터 합성을 지원

ImageDataGenerator(zoom_range = [0.5,1.0])
이런식으로 줌인 줌아웃을 하거나
ImageDataGenerator(rotation_range=90)
데이터를 조금 다르게 한다.(각도나 꺾임)

2. Ensemble 모델

한번만 수행되는 것이 아닌 같은 input으로 여러개의 클래스를 만들어 수행하여 그 결과들을 마지막에 merge하는 방식 다 합쳐서 최종 모델을 만드는 것.

마지막에 최종적으로 softmax활성화 함수를 이용하기 때문에 각 클래스별로 결과 확률값들이 있을 것이다. 이것을 모든 클래스를 더하면 최종적인 결과 확률 데이터가 있는데 이때 확률이 가장 큰 것으로 결과를 예측하는 것이다.


=============================


RNN
Recurrent Neural NEtwork
순환신경망 : 자연어같은 처리에 사용한다

앞시간의 시간적인 종속성이 있을 때 처리하기 위해
(동영상이나 말 같이 앞의 데이터에 따라 뒷 데이터에 영향을 주는 경우 순환 신경망을 사용하게 된다.)
즉 시간적인 순서를 갖는 시퀀스나 시퀀스의 길이가 가변적이다.

주가예측과 같은 시계열 예측이나 자연어 처리(말, 음성)등에 RNN을 사용한다.

RNN
연속적인 데이터(시퀀스 데이터)
한개의 단어로는 시퀀스 데이터를 이해할 수 없다

현재의 단어와 이전 단어의 조합으로 전체적인 문장의 흐름을 이해.

NN/CNN은 이전 상태에 대한 내용이 없다.

입력과 A 출력이 있는데 A부분이 계속 돌게 된다. 즉 내가 받은 입력값에 대한 출력이 다시 입력으로 같이 들어오게 된다.(순환구조)

RNN은 시퀀스 데이터를 처리한다.

x1값에 대한 모델이 x2가 들어갈때 히든레이어 A에 같이 들어간다. 이게 연속적으로 일어나 이전값들의 모델이 같이 연속적으로 가능한 것이다.


현재 상태의 모델을 만들때 이전 모델에 대한것을 고려 하며 만들게 되는 것.

RNN은 step을 거칠때마다 어떤 결과를 예측

이전까지는 보통 y = Wx + b형태였다면
RNN은
ht = fw(ht-1,xt)로 fw라는 웨잇함수에 집어넣는것.

ht = tanh(Whh*ht-1 + Wxh*xt)
Whh는 일반적인 x에대한 웨잇이 아닌 이전 값에 대한 웨잇을 뜻함

RNN은 보통 활성화함수로 tanh를 많이 쓴다.

다양한 RNN형태
one to one(바닐라 RNN)
one to many(비디오에 대한 설명같은것)
many to one(리뷰 문장들을 봣을때 좋은지 나쁜지)
many to many(번역, 형태소 분석등)
many to many(입출력이 갯수가 같음)


RNN구현
바닐라 RNN 구현(Keras.SimpleRNN)

각각 히든스테이트에서 출력을 할것인지 안할것인지
return_sequences = False하면 마지막 한번만 출력
True면 모든 클래스에서 출력


model.add(SimpleRNN(50, return_sequences=False, input_shape=(4,1)))

simple rnn울 50개 만들고 return 시퀀스 는 False로 한다 그리고 input shape을 지정해준다(4,1)

model.fit(X,Y,epochs=200, verbose=2)
200번 반복과 verbose로 값을 보여준다.







